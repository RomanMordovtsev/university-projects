{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeWUFzTxemI9",
        "outputId": "49ca69bc-53f6-442e-f5d6-36fba7d74e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete. Plots saved.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data loading and preparation\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "X_train = train_data['x'].values.reshape(-1, 1)\n",
        "y_train = train_data['r'].values.reshape(-1, 1)\n",
        "X_test = test_data['x'].values.reshape(-1, 1)\n",
        "y_test = test_data['r'].values.reshape(-1, 1)\n",
        "\n",
        "# Add bias term\n",
        "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "# Single Layer Perceptron\n",
        "class SingleLayerPerceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
        "        self.weights = np.random.randn(input_size, 1)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.weights\n",
        "\n",
        "    def train(self, X, y):\n",
        "        mse_history = []\n",
        "        for epoch in range(self.epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            error = y_pred - y\n",
        "            mse = np.mean(error**2)\n",
        "            mse_history.append(mse)\n",
        "            gradient = X.T @ error / len(X)\n",
        "            self.weights -= self.learning_rate * gradient\n",
        "        return mse_history\n",
        "\n",
        "# Multi Layer Perceptron\n",
        "class MultiLayerPerceptron:\n",
        "    def __init__(self, input_size, hidden_size, learning_rate=0.01, epochs=1000):\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2./(input_size + hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, 1) * np.sqrt(2./(hidden_size + 1))\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def tanh_derivative(self, x):\n",
        "        return 1 - np.tanh(x)**2\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.hidden_input = X @ self.W1\n",
        "        self.hidden_output = self.tanh(self.hidden_input)\n",
        "        self.output = self.hidden_output @ self.W2\n",
        "        return self.output\n",
        "\n",
        "    def train(self, X, y):\n",
        "        mse_history = []\n",
        "        for epoch in range(self.epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            error = y_pred - y\n",
        "            mse = np.mean(error**2)\n",
        "            mse_history.append(mse)\n",
        "\n",
        "            d_output = error / len(X)\n",
        "            d_W2 = self.hidden_output.T @ d_output\n",
        "\n",
        "            d_hidden = d_output @ self.W2.T * self.tanh_derivative(self.hidden_input)\n",
        "            d_W1 = X.T @ d_hidden\n",
        "\n",
        "            self.W2 -= self.learning_rate * d_W2\n",
        "            self.W1 -= self.learning_rate * d_W1\n",
        "\n",
        "        return mse_history\n",
        "\n",
        "# Train and evaluate models\n",
        "def main():\n",
        "    # Initialize models\n",
        "    slp = SingleLayerPerceptron(input_size=X_train.shape[1], learning_rate=0.01, epochs=1000)\n",
        "    mlp_2 = MultiLayerPerceptron(input_size=X_train.shape[1], hidden_size=2, learning_rate=0.01, epochs=1000)\n",
        "    mlp_4 = MultiLayerPerceptron(input_size=X_train.shape[1], hidden_size=4, learning_rate=0.01, epochs=1000)\n",
        "    mlp_8 = MultiLayerPerceptron(input_size=X_train.shape[1], hidden_size=8, learning_rate=0.01, epochs=1000)\n",
        "\n",
        "    # Train models\n",
        "    slp_mse = slp.train(X_train, y_train)\n",
        "    mlp_2_mse = mlp_2.train(X_train, y_train)\n",
        "    mlp_4_mse = mlp_4.train(X_train, y_train)\n",
        "    mlp_8_mse = mlp_8.train(X_train, y_train)\n",
        "\n",
        "    # Test models\n",
        "    def test_model(model, X, y):\n",
        "        y_pred = model.forward(X)\n",
        "        return np.mean((y_pred - y)**2)\n",
        "\n",
        "    slp_test_mse = test_model(slp, X_test, y_test)\n",
        "    mlp_2_test_mse = test_model(mlp_2, X_test, y_test)\n",
        "    mlp_4_test_mse = test_model(mlp_4, X_test, y_test)\n",
        "    mlp_8_test_mse = test_model(mlp_8, X_test, y_test)\n",
        "\n",
        "    # Plot model outputs\n",
        "    models = [slp, mlp_2, mlp_4, mlp_8]\n",
        "    plot_model_outputs(models, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Plot learning curves\n",
        "    train_mse = [slp_mse, mlp_2_mse, mlp_4_mse, mlp_8_mse]\n",
        "    plot_learning_curves(train_mse)\n",
        "\n",
        "    # Plot complexity vs error\n",
        "    test_mse = [slp_test_mse, mlp_2_test_mse, mlp_4_test_mse, mlp_8_test_mse]\n",
        "    plot_complexity_vs_error(test_mse)\n",
        "\n",
        "    print(\"Training complete. Plots saved.\")\n",
        "\n",
        "def plot_model_outputs(models, X_train, y_train, X_test, y_test):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    titles = ['Single-Layer Perceptron', 'MLP with 2 Hidden Units',\n",
        "              'MLP with 4 Hidden Units', 'MLP with 8 Hidden Units']\n",
        "\n",
        "    sorted_idx = np.argsort(X_test[:, 1])\n",
        "    X_test_sorted = X_test[sorted_idx]\n",
        "    y_test_sorted = y_test[sorted_idx]\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.scatter(X_train[:, 1], y_train, color='blue', label='Training Data', alpha=0.5)\n",
        "        plt.scatter(X_test[:, 1], y_test, color='green', label='Test Data', alpha=0.5)\n",
        "        y_pred = model.forward(X_test_sorted)\n",
        "        plt.plot(X_test_sorted[:, 1], y_pred, color='red', linewidth=2, label='Model Prediction')\n",
        "        plt.title(titles[i])\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel('r')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_outputs.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_learning_curves(train_mse):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    labels = ['SLP', 'MLP-2', 'MLP-4', 'MLP-8']\n",
        "\n",
        "    for mse, label in zip(train_mse, labels):\n",
        "        plt.plot(mse, label=label)\n",
        "\n",
        "    plt.title('Learning Curves (MSE vs Epochs)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('learning_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_complexity_vs_error(test_mse):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    hidden_units = [0, 2, 4, 8]  # 0 for SLP\n",
        "\n",
        "    plt.plot(hidden_units, test_mse, marker='o')\n",
        "    plt.title('Model Complexity vs Test Error')\n",
        "    plt.xlabel('Number of Hidden Units')\n",
        "    plt.ylabel('Test MSE')\n",
        "    plt.grid(True)\n",
        "    plt.savefig('complexity_vs_error.png')\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}